{"cells":[{"cell_type":"markdown","metadata":{"id":"HGk-VZf8QQnK"},"source":["# Implementing dual input/output units and error masking"]},{"cell_type":"markdown","metadata":{"id":"VQ_tSMNE4Kg2"},"source":["This module introduces two additional concepts common in cognitive neural network models. First, visible units (where activation patterns are directly specified by the environment) should be able to both encode input from the environment *and* target values for learning. Second, often we do not want all output units to always contribute to model loss&mdash;perhaps on a given training example and each timestep we only want some subset of output units to get error. Neither functionality is straighforwardly implemented in the development environment; the current module illustrates how the toolbox supports both functions, and how they can be built from scratch with tools introduced earlier."]},{"cell_type":"markdown","metadata":{"id":"eqQpIGmcOAF4"},"source":["## The hub-and-spokes model as an example"]},{"cell_type":"markdown","metadata":{"id":"Y94nZkg5N28e"},"source":["The hub-and-spokes model is a model of cross-modal semantic representation and processing that has been useful for understanding healthy and disordered semantic processing (see [Rogers et al., 2004](http://concepts.psych.wisc.edu/papers/RogersETAL04_PR.pdf)). The model can take either visual or verbal inputs. Units in the visual layer locally encode visual features of objects, while those in the verbal layer locally encode propositional statements about objects (e.g. *is big*, *is furry*, *can fly*, *is a bird*, etc.). The model receives direct visual or verbal input about an object and must then generate other, unspecified visual or verbal information about the item.\n","\n","Like PMSP, this model is fully continuous and recurrent. In PMSP, however, the model always takes an orthographic input and returns a phonological output. In hub-and-spokes, both the visual and the verbal layers sometimes serve as input (environment directly stimulates these units), and other times as outputs (environment provides targets for learning on these units). Many other models in cognitive neuroscience employ architectures of this kind, which are not straightforward to implement in Keras/Tensorflow. This module illustrates one approach, using the hub-and-spokes model as an example.\n","\n","The figure below shows how the model is typically depicted in figures (top) and how the computation can be unrolled in time, using multi-input time-averaging as the activation function. The orange squares are visible layers that get direct input from the training/testing environment and also have target values specified. The blue rectangles are input layers that can be hard-clamped. Each sends a single connection with a fixed positive weight to the corresponding output unit, so when an input unit is active it essentially provides positive input to just the corresponding output unit. The output unit takes this along with other inputs and sets its activation according to the usual activation update function. Only the output units get targets.\n","\n","The unfolded illustration makes it clear that target values must be applied to layers that are *not* the final layer of the model (ie, they are not the last to compute activations within a time-step). In each time step, units in the orange layers should be updated before the hidden units (white circle). Otherwise the model is similar to those developed in earlier modules. A key question is how to specify target values for layers in an RNN that are _not_ the last layer specified.\n"]},{"cell_type":"markdown","metadata":{"id":"Pk_lhIiqPrtq"},"source":["Model summary:\n","\n","Forward pass: take whatever information available at hand, and output hub and spokes activations all the time.\n","\n","Backward pass: similar to forward pass, take whatever available as training signal, inject loss at appropriate units (ignoring the masking value) then sum across all axis."]},{"cell_type":"markdown","metadata":{"id":"1ImQjEymraPg"},"source":["![model architechture](https://drive.google.com/uc?id=1mN62Dn_ugWSEYF007FPGRRmEk-QVZRWN)"]},{"cell_type":"markdown","metadata":{"id":"uMvjCEcdapWg"},"source":["### Create Hub-and-Spokes model using high-level API\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3z0fP-3bEnn"},"outputs":[],"source":["!pip install connectionist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwhIVopTa5gC"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from connectionist.models import HubAndSpokes\n","from connectionist.losses import MaskedBinaryCrossEntropy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoRH9XrVi_4L"},"outputs":[],"source":["model = HubAndSpokes(\n","    tau = 0.1, \n","    hub_name = 'semantics',\n","    hub_units = 64, \n","    spoke_names = ['visual_descriptors', 'visual_features'],  # you can have more than 2 spokes\n","    spoke_units = [152, 64]  # must match the no. of spoke_names\n","    )"]},{"cell_type":"markdown","metadata":{"id":"GKOkjO1ljKLX"},"source":["### A convienient function to get data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93SPxLIOr1uF"},"outputs":[],"source":["def get_data(x_names, y_names, \n","             batch_size = 100, max_ticks = 10, \n","             visual_descriptor_units = 152, visual_feature_units = 64, semantic_units = 64):\n","    \"\"\"Get dummy data for hub-and-spokes model.\"\"\"\n","\n","    data = {\n","        'semantics': tf.random.uniform((batch_size, max_ticks, semantic_units)),\n","        'visual_descriptors': tf.random.uniform((batch_size, max_ticks, visual_descriptor_units)),\n","        'visual_features': tf.random.uniform((batch_size, max_ticks, visual_feature_units)),\n","    }\n","\n","    return (\n","        {k: v for k, v in data.items() if k in x_names},\n","        {k: v for k, v in data.items() if k in y_names}\n","    )\n","\n","\n","x_train, y_train = get_data(x_names=['visual_descriptors', 'visual_features'], y_names=['semantics'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgTFbSLhjHE9"},"outputs":[],"source":["y_pred = model(x_train)\n","[f\"{k}: {v.shape}\" for k, v in y_pred.items()]"]},{"cell_type":"markdown","metadata":{"id":"NTwzWsWbZ_FX"},"source":["### Building an entire Hub-and-Spokes (HNS) layer\n","\n","Now that we know we can just call the `HubAndSpokes()` model at a high level, let's look at what is inside the model in detail. As before we will first consider the RNN cell (what happens in one time step), then how a cell is used to comprise an RNN layer (the loop over time steps).\n","\n","Note that, for simplicity, below HNS layer example only supports two spokes, but in the `connectionist.layers.HNSLayer` and `connectionist.models.HubAndSpokes` supports any number of spokes, the input arguements are slightly different. "]},{"cell_type":"markdown","metadata":{"id":"65rN7Xu_N28f"},"source":["### Architecture"]},{"cell_type":"markdown","metadata":{"id":"tT885-igE7d5"},"source":["![model architechture](https://drive.google.com/uc?id=1V_poXKLZ5udEI4Eh0pgOz4zoYEyN-lbO)"]},{"cell_type":"markdown","metadata":{"id":"tNzZ_rTHE7d8"},"source":["### Recap on MultiInputTimeAveraging layer (MITA)\n","\n","Before using MITA as a building block in the hub-and-spokes model, let's recap how it works. \n","\n","see [MITA docs](https://jasonlo.github.io/connectionist/layers/MultiInputTimeAveraging/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tg7re6XhN28h"},"outputs":[],"source":["from typing import List, Dict, Union, Optional\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from connectionist.layers import MultiInputTimeAveraging"]},{"cell_type":"markdown","metadata":{"id":"ORPGCD_vN28h"},"source":["Using `MultiInputTimeAveraging` to create $a_t = \\tau \\cdot act(\\sum_i x_i + b) + (1-\\tau) \\cdot a_{t-1}$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPzbjzOGN28j"},"outputs":[],"source":["mita = MultiInputTimeAveraging(tau=0.1, average_at='after_activation', activation='sigmoid', use_bias=True)"]},{"cell_type":"markdown","metadata":{"id":"h052RC54Cso4"},"source":["Suppose we have three RNN units receiving net inputs from two different sources (say, two other layers). The RNN units should add the net inputs together and update its activation according to the MITA function. To see this in action, we create two tensors, each capturing the net inputs to the three units from one source. Applying `mita` to a list of those two tensors then updates the activations of the three units:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jky9QkX6N28j"},"outputs":[],"source":["x1 = tf.ones((1, 3))  # net inputs for three units from one source\n","x2 = tf.ones((1, 3)) - 0.5  # net inputs to the same three units from another source\n","\n","mita([x1, x2])"]},{"cell_type":"markdown","metadata":{"id":"yI1nlhz2DbZ1"},"source":["Calling the object on a list containing the two net input tensors generates an output tensor containing the updated activations of units in the `mita` object. "]},{"cell_type":"markdown","metadata":{"id":"cHrdCX68N28k"},"source":["\n","This layer contains only one bias matrix:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2M3OSmaN28l"},"outputs":[],"source":["mita.weights"]},{"cell_type":"markdown","metadata":{"id":"_TwVVIEPN28l"},"source":["...and stores a vector of states (ie activations), which are re-used as the 'prior state' $a_{t-1}$ in future updates:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B80TLgklN28l"},"outputs":[],"source":["mita.states"]},{"cell_type":"markdown","metadata":{"id":"QJB0NxmhE5Wt"},"source":["Why is this the activaton? Since this is the first time the units were updated, the prior state is set to zero by default. Each unit is receiving an input of +1 from x1 and +.5 from x2. The bias weight is set to 0.0 by default, so these are the only inputs, and the total current net input is +1.5. Passing this through the sigmoid function gives an activation $a_t\\approx0.8175$&mdash; this is the activation the unit would adopt with instantaneous updating. With time-averaging, however, the unit activation will update to the weighted average of $(1 - \\tau) a_{t-1} + \\tau a_t$. As noted, the prior activation $a_{t-1}$ is 0.0, and when we created `mita` we set $\\tau=0.1$. So, the new activation is $\\tau a_t \\approx 0.1 * 0.8175 = 0.08175$. "]},{"cell_type":"markdown","metadata":{"id":"46bWK1r-N28m"},"source":["By default `mita` will retain this activation vector for use as the prior-state in computations for new updates. To clear these states (for instance, at the end of an RNN loop processing a full sequence if you do not want them to persist to a new sequence) , use the `mita` reset method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgX6yHcPN28m"},"outputs":[],"source":["mita.reset_states()\n","print(mita.states)"]},{"cell_type":"markdown","metadata":{"id":"vamREBDUN28m"},"source":["The following code block uses [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp) to simulate repeatedly calling `mita` in an RNN loop, keeping the inputs static for the whole time. It also plots how the activation changes with successive updates in the loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHlA8PJGE7d-"},"outputs":[],"source":["y = np.stack([mita([x1, x2]).numpy()[0] for _ in range(30)])  \n","plt.plot(y)\n","plt.title(\"Activation over time.\")\n"]},{"cell_type":"markdown","metadata":{"id":"E1JVbsCtN28n"},"source":["Notice that `mita` automatically keeps its current activation, then uses this as the \"prior state\" when updating its new activation. That is, the activation state persists over multiple calls, unless the reset method is called. Also, recall that the net inputs are specifying that the unit should eventually adopt an activation value of 0.8175. With the time-averaged updating function, you can see that the unit activation is approaching that limit.\n","\n","What if the input changes? Let's increase it to a very high number by adding 1000 to one of the input sources, then continue updating the RNN activation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSwDYo0wN28n"},"outputs":[],"source":["y = np.stack([mita([x1+1000, x2]).numpy()[0] for _ in range(30)])  \n","plt.plot(y)\n","plt.title(\"Activation cap at 1.\")"]},{"cell_type":"markdown","metadata":{"id":"2eAHAxyQN28o"},"source":["Notice the activation begins near 0.8, as that was the last activation value computed in the cell above. Rather than continuing to flatten out, the activation instead leaps up and approaches 1.0, the upper limit of the sigmoid function.\n","\n","Now let's return to the original input and continue updating the RNN activation to see how the activation ramps down:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jnZcjNMN28o"},"outputs":[],"source":["y = np.stack([mita([x1, x2]).numpy()[0] for _ in range(30)])  \n","plt.plot(y)\n","plt.title(\"Ramping down is also slow due to the time-averaging mechanism.\")"]},{"cell_type":"markdown","metadata":{"id":"DBj0ABE_w9pc"},"source":["Finally, let's give the cell a highly negative input:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6pc4jbJw31j"},"outputs":[],"source":["y = np.stack([mita([x1 - 1000, x2]).numpy()[0] for _ in range(30)])  \n","plt.plot(y)\n","plt.title(\"Ramping down is also slow due to the time-averaging mechanism.\")"]},{"cell_type":"markdown","metadata":{"id":"VDHYVEVxN28o"},"source":["You can see it now gets pushed toward 0.0, the lower limit of the sigmoid function. For further details, you can refer to the source code."]},{"cell_type":"markdown","metadata":{"id":"j7mY9HJVE7eA"},"source":["### Building a Spoke from MultiInputTimeAveraging\n","\n","With this refresher, let's look at constructing the hub-and-spokes model, beginning with a single \"spoke\" (ie, a single input/output layer)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5BMSvj6E7eA"},"outputs":[],"source":["class Spoke(tf.keras.layers.Layer):\n","    \"\"\"A spoke in the hub-and-spokes model.\"\"\"\n","\n","    def __init__(self, tau: float, units: int) -> None:\n","        super().__init__()\n","        self.tau = tau\n","        self.units = units  # Technically can infer from input, but it will make life easier when input is None. i.e., conform with flexible input.  \n","        self.time_averaging = MultiInputTimeAveraging(tau=self.tau, average_at='after_activation', activation='sigmoid', use_bias=True)\n","\n","    def call(self, inputs: tf.Tensor=None, cross_tick_states: List[tf.Tensor]=None):  # to avoid confusing with `self.time_averaging.states` (a_{t-1}), I use a new name `cross_tick_states` here to represent the red arrows (cross ticks projection) in the figure.\n","        \"\"\"Call the spoke.\n","        \n","        Args:\n","            inputs: clamped input (blue node)\n","            cross_tick_states: states from the red arrows (cross ticks projection), a_i w_{ij}.\n","        \"\"\"\n","        if inputs is None:\n","            inputs = tf.zeros((1, self.units))\n","\n","        if cross_tick_states is None:\n","            # Green only\n","            return self.time_averaging([inputs])  \n","        \n","        # Red, red, green\n","        return self.time_averaging([inputs, *cross_tick_states])  # Note that we end up merging inputs and cross_tick_states, spearating them are just for clarity. \n","    def reset_states(self):\n","        self.time_averaging.reset_states()\n","          \n"]},{"cell_type":"markdown","metadata":{"id":"45J83CfYUD86"},"source":["- A `Spoke` is just a thin wrapper of `MultiInputTimeAveraging`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zfu-LKDUE7eB"},"outputs":[],"source":["spoke = Spoke(tau=0.1, units=3)"]},{"cell_type":"markdown","metadata":{"id":"Jg3iIcyuE7eB"},"source":["Test the spoke with no input at all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aeYOm3XE7eB"},"outputs":[],"source":["spoke.reset_states()\n","spoke(None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vSSvoz0F1aE"},"outputs":[],"source":["[w for w in spoke.weights]"]},{"cell_type":"markdown","metadata":{"id":"NbWkBq1JE7eB"},"source":["Test spoke with random input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Patr-oAE7eC"},"outputs":[],"source":["spoke.reset_states()\n","x = tf.random.uniform((1, 3))\n","y = [spoke(x).numpy()[0] for _ in range(30)]\n","y = np.stack(y)\n","plt.plot(y)\n","plt.title(\"Activation over time from random inputs without cross-tick projection.\")"]},{"cell_type":"markdown","metadata":{"id":"ZsAzpugeE7eC"},"source":["Test spoke with random input and random cross-tick projection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiEKVG0fE7eC"},"outputs":[],"source":["spoke.reset_states()\n","cross_tick_states = [tf.random.uniform((1, 3)) for _ in range(2)]\n","y = [spoke(x, cross_tick_states).numpy()[0] for _ in range(30)]  # Using the same input as above\n","plt.plot(y)\n","plt.title(\"Activation over time from random inputs with cross-tick projection.\")\n"]},{"cell_type":"markdown","metadata":{"id":"y5NJiilhE7eD"},"source":["### Hub-and-spokes cell (HNSCell)"]},{"cell_type":"markdown","metadata":{"id":"v_Dn8C4TE7eD"},"source":["Now, we have a spoke, we can define the compute in one time step of the hub-and-spokes model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDXOEwwkE7eD"},"outputs":[],"source":["class HNSCell(tf.keras.layers.Layer):\n","\n","    def __init__(self, tau: float, hub_units: int, spoke1_units: int, spoke2_units:int) -> None:\n","        super().__init__()\n","        self.tau = tau\n","        self.hub_units = hub_units\n","        self.spoke1_units = spoke1_units\n","        self.spoke2_units = spoke2_units\n","\n","\n","    def build(self, input_shape) -> None:\n","\n","        # Hub\n","        self.hub = MultiInputTimeAveraging(tau=self.tau, average_at='after_activation', activation='sigmoid', use_bias=True)\n","        self.w_hh = self.add_weight(shape=(self.hub_units, self.hub_units), initializer=\"random_normal\", trainable=True)  # red\n","        self.w_s1h = self.add_weight(shape=(self.spoke1_units, self.hub_units), initializer=\"random_normal\", trainable=True)  # blue\n","        self.w_s2h = self.add_weight(shape=(self.spoke2_units, self.hub_units), initializer=\"random_normal\", trainable=True)  # blue\n","\n","        # Spoke 1\n","        self.spoke1 = Spoke(tau=self.tau, units=self.spoke1_units)\n","        self.w_s1s1 = self.add_weight(shape=(self.spoke1_units, self.spoke1_units), initializer=\"random_normal\", trainable=True) # red\n","        self.w_hs1 = self.add_weight(shape=(self.hub_units, self.spoke1_units), initializer=\"random_normal\", trainable=True)  # red\n","        \n","        # Spoke 2\n","        self.spoke2 = Spoke(tau=self.tau, units=self.spoke2_units)\n","        self.w_s2s2 = self.add_weight(shape=(self.spoke2_units, self.spoke2_units), initializer=\"random_normal\", trainable=True)  # red\n","        self.w_hs2 = self.add_weight(shape=(self.hub_units, self.spoke2_units), initializer=\"random_normal\", trainable=True)  # red\n","\n","        self.built = True\n","        \n","    def call(self, inputs1=None, inputs2=None, last_act_hub = None, last_act_spoke1=None, last_act_spoke2=None) -> List[tf.Tensor]:\n","        \"\"\"Returns a list of activations: [act_spoke1, act_spoke2, act_hub].\"\"\"\n","\n","        # Calculate net inputs via red arrows (cross-tick projections)\n","        hs1 = None if last_act_hub is None else last_act_hub @ self.w_hs1\n","        s1s1 = None if last_act_spoke1 is None else last_act_spoke1 @ self.w_s1s1\n","        hs2 = None if last_act_hub is None else last_act_hub @ self.w_hs2\n","        s2s2 = None if last_act_spoke2 is None else last_act_spoke2 @ self.w_s2s2\n","        hh = None if last_act_hub is None else last_act_hub @ self.w_hh\n","\n","        # Calculate spoke activations\n","        cross_tick_spoke1 = [s for s in [hs1, s1s1] if s is not None]\n","        act_spoke1 = self.spoke1(inputs1, cross_tick_states=cross_tick_spoke1)\n","\n","        cross_tick_spoke2 = [s for s in [hs2, s2s2] if s is not None]\n","        act_spoke2 = self.spoke2(inputs2, cross_tick_states=cross_tick_spoke2)\n","\n","        # Calculate net inputs via blue arrows (within-tick projection)\n","        s1h = act_spoke1 @ self.w_s1h  \n","        s2h = act_spoke2 @ self.w_s2h\n","\n","        # calculate hub activation\n","        inputs_to_hub = [s for s in [s1h, s2h, hh] if s is not None]\n","        act_hub = self.hub(inputs_to_hub)\n","\n","        return [act_spoke1, act_spoke2, act_hub]\n","\n","    def reset_states(self) -> None:\n","        self.hub.reset_states()\n","        self.spoke1.reset_states()\n","        self.spoke2.reset_states()\n"]},{"cell_type":"markdown","metadata":{"id":"6ebklPaiN28r"},"source":["Test cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwrIf7x6E7eD"},"outputs":[],"source":["cell = HNSCell(tau=0.1, hub_units=5, spoke1_units=3, spoke2_units=3)"]},{"cell_type":"markdown","metadata":{"id":"j6VkHL4mN28r"},"source":["No input at all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZ9N50CwN28s"},"outputs":[],"source":["cell(inputs1=None, inputs2=None)"]},{"cell_type":"markdown","metadata":{"id":"iT2wgzLlN28s"},"source":["Having inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jac7HS7HE7eE"},"outputs":[],"source":["cell(\n","    inputs1=tf.random.uniform((1, 3)),\n","    inputs2=tf.random.uniform((1, 3)),\n",")"]},{"cell_type":"markdown","metadata":{"id":"giQSeLlNN28s"},"source":["Having inputs and cross-tick projection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4WaCwJ-Q_NN"},"outputs":[],"source":["cell(\n","    inputs1=tf.random.uniform((1, 3)),\n","    inputs2=tf.random.uniform((1, 3)),\n","    last_act_hub=tf.random.uniform((1, 5)),\n","    last_act_spoke1=tf.random.uniform((1, 3)),\n","    last_act_spoke2=tf.random.uniform((1, 3)),\n",")"]},{"cell_type":"markdown","metadata":{"id":"V9mNxePaE7eE"},"source":["### Unrolling the HNSCell to create a HNS layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoSHJjlPE7eE"},"outputs":[],"source":["class HNSLayer(tf.keras.layers.Layer):\n","\n","    def __init__(self, tau: float, hub_units: int, spoke1_units: int, spoke2_units:int) -> None:\n","        super().__init__()\n","        self.tau = tau\n","        self.hub_units = hub_units\n","        self.spoke1_units = spoke1_units\n","        self.spoke2_units = spoke2_units\n","        \n","    def build(self, input_shape) -> None:\n","        self.cell = HNSCell(tau=self.tau, hub_units=self.hub_units, spoke1_units=self.spoke1_units, spoke2_units=self.spoke2_units)\n","        self.built = True\n","\n","    def call(self, inputs1, inputs2) -> List[tf.Tensor]:\n","        \"\"\"Returns a list of activations: [act_spoke1, act_spoke2, act_hub].\"\"\"\n","\n","        batch_size = inputs1.shape[0]\n","        max_ticks = inputs1.shape[1]\n","\n","        # Initialize activations in hub and spokes\n","        h = tf.zeros((batch_size, self.hub_units))\n","        s1 = tf.zeros((batch_size, self.spoke1_units))\n","        s2 = tf.zeros((batch_size, self.spoke2_units))\n","\n","        # Make containers for outputs\n","        output_spoke1 = tf.TensorArray(tf.float32, size=max_ticks)\n","        output_spoke2 = tf.TensorArray(tf.float32, size=max_ticks)\n","        output_hub = tf.TensorArray(tf.float32, size=max_ticks)\n","\n","        for t in range(max_ticks):\n","            s1, s2, h = self.cell(\n","                inputs1=inputs1[:, t],\n","                inputs2=inputs2[:, t],\n","                last_act_hub=h,\n","                last_act_spoke1=s1,\n","                last_act_spoke2=s2,\n","            )\n","\n","            output_spoke1 = output_spoke1.write(t, s1)\n","            output_spoke2 = output_spoke2.write(t, s2)\n","            output_hub = output_hub.write(t, h)\n","\n","        self.cell.reset_states()\n","\n","        output_spoke1 = tf.transpose(output_spoke1.stack(), [1, 0, 2])\n","        output_spoke2 = tf.transpose(output_spoke2.stack(), [1, 0, 2])\n","        output_hub = tf.transpose(output_hub.stack(), [1, 0, 2])\n","\n","        return {\n","            \"hub\": output_hub,\n","            \"spoke1\": output_spoke1,\n","            \"spoke2\": output_spoke2,\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HK3ajt8E7eF"},"outputs":[],"source":["manual_model = HNSLayer(tau=0.1, hub_units=5, spoke1_units=3, spoke2_units=4)\n","\n","manual_model(\n","    inputs1=tf.random.uniform((1, 10, 3)),\n","    inputs2=tf.random.uniform((1, 10, 4))\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"fORm_QnGN28u"},"source":["We illustrated how to create hub-and-spokes model architecture above."]},{"cell_type":"markdown","metadata":{"id":"KArYnP8bRahn"},"source":["## Model Training"]},{"cell_type":"markdown","metadata":{"id":"mz00ykk_I0-j"},"source":["Since the representations have some un-used filler slots, they are not suppose to providing training signal to the model. Therefore, we need to mask those values when calculating loss. We will use `connectionist.losses.MaskedBinaryCrossEntropy` to do that."]},{"cell_type":"markdown","metadata":{"id":"QiI0tLf1swpj"},"source":["### Using high-level API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjjttlEwE7eF"},"outputs":[],"source":["from connectionist.losses import MaskedBinaryCrossEntropy\n","\n","x_train, y_train = get_data(x_names=['visual_descriptors', 'visual_features'], y_names=['semantics'])\n","\n","loss_fn = MaskedBinaryCrossEntropy(mask_value=9)  \n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n","\n","model = HubAndSpokes(\n","    tau = 0.1, \n","    hub_name = 'semantics',\n","    hub_units = 64, \n","    spoke_names = ['visual_descriptors', 'visual_features'], \n","    spoke_units = [152, 64]\n","    )\n","\n","model.compile(optimizer=optimizer, loss=loss_fn)\n","history = model.fit(x_train, y_train, epochs=10, batch_size=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0F3EQk0LAcE"},"outputs":[],"source":["plt.plot(history.history['loss'])"]},{"cell_type":"markdown","metadata":{"id":"uCddpOTjs_32"},"source":["What's inside the loss function and the training loop looks like if we do it manually?"]},{"cell_type":"markdown","metadata":{"id":"US4l9yrMN28v"},"source":["### Custom loss function: Binary cross-entropy with masking"]},{"cell_type":"markdown","metadata":{"id":"8XhCmxpMN28v"},"source":["Binary cross-entropy formula\n","\n","$$H_p(q) = - \\frac{1}{N} \\sum_{i=1}^{N}y_i \\cdot \\log(p(y_i)) + (1-y_i) \\cdot \\log(1-p(y_i))$$\n","\n","where $y_i$ is the target, and $p(y_i)$ is the prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H11BNP1nN28v"},"outputs":[],"source":["class MaskedBinaryCrossEntropy(tf.keras.losses.Loss):\n","    \"\"\"Compute Binary Cross-Entropy with mask.\n","\n","    Args:\n","        y_true: target y with shape (batch_size, seq_len, feature)\n","        y_pred: predicted y with shape (batch_size, seq_len, feature)\n","        mask_value: value in y_true to be masked\n","    Returns:\n","        Loss value with shape (batch_size)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        mask_value: int = None,\n","        name=\"masked_binary_crossentropy\",\n","        reduction=\"none\",\n","        **kwargs\n","    ) -> None:\n","        super().__init__(name=name, reduction=reduction, **kwargs)\n","        self.mask_value = mask_value\n","\n","    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n","        epsilon = tf.keras.backend.epsilon()  # very small value to avoid log(0)\n","        cross_entropy = y_true * tf.math.log(y_pred + epsilon)\n","        cross_entropy = cross_entropy + (1 - y_true) * tf.math.log(1 - y_pred + epsilon)\n","\n","        if self.mask_value:\n","            mask = tf.cast(\n","                tf.where(y_true == self.mask_value, 0, 1), tf.float32\n","            )  # create mask\n","        else:\n","            mask = tf.ones_like(cross_entropy)  # All inclusive mask if value is none\n","\n","        cross_entropy = mask * cross_entropy  # zero out the masked values\n","        cross_entropy = tf.reduce_sum(\n","            cross_entropy, axis=[1, 2]\n","        )  # sum over all units (axis 2) and time steps (axis 1)\n","        return -cross_entropy / (\n","            epsilon + tf.reduce_sum(mask, axis=[1, 2])\n","        )  # - (1/N) sum(y * log(p(y)) + (1-y) * log(1-p(y)))"]},{"cell_type":"markdown","metadata":{"id":"NMjdNp1uWpCe"},"source":["### Optimizer and training function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkJ8JI4xgbT4"},"outputs":[],"source":["x_train = {\n","    'spoke1' : tf.random.uniform((1, 2, 3)),  # clamped input to spoke1\n","    'spoke2' : tf.random.uniform((1, 2, 4))  # clamped input to spoke2\n","}\n","\n","\n","y_train= {\n","    'hub': tf.convert_to_tensor(\n","        [[[1, 0, 9, 9, 9], [0, 9, 9, 9, 9]], [[1, 1, 0, 0, 0], [0, 1, 1, 1, 1]]],\n","        dtype=tf.float32  # target for hub activations\n","    )\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Yxif3LAP4OI"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n","masked_cross_entropy = MaskedBinaryCrossEntropy(mask_value=9)\n","\n","@tf.function\n","def train_step(x_train: Dict[str, tf.Tensor], y_train: Dict[str, tf.Tensor]) -> tf.Tensor:\n","    \"\"\"Custom training loop for HNS model.\"\"\"\n","\n","    with tf.GradientTape() as tape:\n","        y_pred = manual_model(inputs1=x_train['spoke1'], inputs2=x_train['spoke2'], training=True)\n","\n","        all_losses = []\n","        for y_name, y_target in y_train.items():  # Only inject error according to y_train (if y_train = {'spoke1': tf.Tensor}, it will only inject error in spoke1)\n","            sum_loss = tf.reduce_sum(masked_cross_entropy(y_true=y_target, y_pred=y_pred[y_name]))  # reduce over batch_size axis\n","            all_losses.append(sum_loss)\n","\n","        loss_value = tf.reduce_sum(all_losses)  # Final loss value is the grand sum over every axis (output layer, batch size, time ticks, units).\n","        \n","    grads = tape.gradient(loss_value, manual_model.trainable_weights)  # compute gradients dL/dw\n","    optimizer.apply_gradients(zip(grads, manual_model.trainable_weights))  # update weights using stock optimizer\n","    return loss_value"]},{"cell_type":"markdown","metadata":{"id":"yfcR4RE4N28y"},"source":["### Train the model manually"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qTX6zdAKQEzH"},"outputs":[],"source":["loss_history = [train_step(x_train, y_train) for _ in range(100)]\n","loss_history = [loss_history.numpy() for loss_history in loss_history]\n","plt.plot(loss_history)"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"tf-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"f55368bc7be0f2238dbef0a99c4d07d77945e5a459017dc2b141ca990cb81374"}}},"nbformat":4,"nbformat_minor":0}