{"cells":[{"cell_type":"markdown","metadata":{"id":"oog4CXqKoYof"},"source":["# Continuous RNN with full recurrence\n","Here we will expand on the continuous recurrent network we developed previously and implement full recurrence between the hidden layer and the output layer. This type of layer structure is sometimes called an \"attractor network\" because the time-varying nature of the learning process simulated and the \"basins of attraction\" that develop as a result of the error landscape that results.\n","\n","The task in this model is the same as in the last module: produce a sequence of letters given a \"word\" as input (i.e., a one-hot representation of the word). The architecture here is based Simulation 3 from Plaut, McClelland, Seidenberg, & Patterson (1996) in Psychological Review. Their model produced a phonological output given an orthographic input. The model we are working with here does something slightly different - though the architectures are otherwise very similar. In their paper they refer to the output layer as containing \"cleanup units\" because of the ways in which the recurrent structure affords a \"cleanup\" process for the phonological outputs in their network.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J70c8n5MIAXu"},"outputs":[],"source":["# Install a pip package created for our course\n","!pip install connectionist"]},{"cell_type":"markdown","metadata":{"id":"DeqDVzyYoYoj"},"source":["## Data\n","\n","The data for this model is identical to the data we used in the last module. While the original PMSP model produced phonological output for an orthographic input, we will continue to simulate the production of a sequence of letters given the one-hot representation of each of 20 words.\n","\n","- Input: word representations, fixed across time. \n","- Output: letter representations, changing across time."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_a3r9WMoYok"},"outputs":[],"source":["from connectionist.data import ToyOP\n","\n","# Data is identical to the last module, import from connectionist.data\n","data = ToyOP()\n","\n","# Give a shorter name for easy access\n","letters = data.letters # this data can be interpreted as letters or sounds. In this example, there isn't a meaningful distinction.\n","words = data.words\n","x_train = data.x_train\n","y_train = data.y_train\n"]},{"cell_type":"markdown","metadata":{"id":"VRnA2f8BoYol"},"source":["## Model creation"]},{"cell_type":"markdown","source":["We will start by calling the `PMSP` model from the `connectionist` package, but we will break it down into individual layers later so you can build it more from scratch yourself. This allows you to work with a higher level wrapper around the code to get a feel for things. Note that we set the value for `tau` here in the call to the `PMSP` layer, which you were exposed to in the module on multi input time-averaging previously.\n","\n","The `PMSP` model is single layer model that contains what we will call a `PMSPLayer` (i.e., `model = Sequential([PMSPLayer(...)])`). The `PMSPCell` is the building block of the `PMSPLayer`, which defines the computing of a single time step in the recurrent process."],"metadata":{"id":"Hk-S9wqWB4y_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_hmCpHZoYom"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Instead of using `connectionist.layers.PMSPLayer` and build the model by Sequential API, \n","# we can directly import the entire PMSP model.\n","from connectionist.models import PMSP\n","model = PMSP(tau=0.1, h_units=10, p_units=9, c_units=5)"]},{"cell_type":"markdown","metadata":{"id":"tFT1V1amoYon"},"source":["### Information flow in the model"]},{"cell_type":"markdown","metadata":{"id":"nBg8XCJCoYoo"},"source":["In the model, one tick of time is required for information to propagate from the one layer to another. This is the result of the \"continuous time\" nature of the information flow in the network. For example, if we start at time $t$ the minimal travel distance from orthographic input ($O$) via the hidden layer ($H$) to the phonological layer ($P$) is 2 ticks: $O$ (at $t$) -> $H$ (at $t+1$) -> $P$ (at $t+2$). The attractor cycle (the portion of the network consisting of $P$ and the cleanup layer, $C$) also requires 2 ticks (again starting at $t$): $P$ (at $t$) -> $C$ (at $t+1$) -> $P$ (at $t+2$)."]},{"cell_type":"markdown","metadata":{"id":"GA7rageFoYoo"},"source":["![model architechture](https://drive.google.com/uc?id=1oUze7Mx-ue7QaaCe90-H-a--Ugsvl-dx)"]},{"cell_type":"markdown","source":["Now, let's tease apart the structure of a `PMSPCell` so you can have a sense of how the layers are structured. As in other model APIs we've seen, the `PMSPCell` layer has a `build()` and a `call()` method, along with `reset_states()`. The layer structure within this cell is considerably more complex than previous cells we've worked with because the information flow is more complex than we've seen previously. For example, the phonology layer recieves inputs from the hidden layer, the cleanup layer, and itself through time."],"metadata":{"id":"1RnuKbIROwTd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5THEjOCYoYop"},"outputs":[],"source":["from connectionist.layers import MultiInputTimeAveraging, TimeAveragedDense\n","\n","class PMSPCell(tf.keras.layers.Layer):\n","    \"\"\"RNN cell for PMSP model.\n","    \n","    See Plaut, McClelland, Seidenberg and Patterson (1996), simulation 3. \n","    \"\"\"\n","    def __init__(self, tau, h_units, p_units, c_units):\n","        super().__init__()\n","        self.tau = tau\n","        self.h_units = h_units\n","        self.p_units = p_units\n","        self.c_units = c_units\n","\n","    def build(self, input_shape):\n","        # Hidden layer\n","        self.o2h = tf.keras.layers.Dense(self.h_units, activation=None, use_bias=False, name='o2h')  # w_oh\n","        self.p2h = tf.keras.layers.Dense(self.h_units, activation=None, use_bias=False, name='p2h')  # w_ph\n","        self.time_averaging_h = MultiInputTimeAveraging(tau=self.tau, average_at=\"after_activation\", activation='sigmoid', name='ta_h')  # bias_h and the time averaging mechanism\n","\n","        # Phonology layer\n","        self.h2p = tf.keras.layers.Dense(self.p_units, activation=None, use_bias=False, name='h2p')  # w_hp\n","        self.p2p = tf.keras.layers.Dense(self.p_units, activation=None, use_bias=False, name='p2p')  # w_pp\n","        self.c2p = tf.keras.layers.Dense(self.p_units, activation=None, use_bias=False, name='c2p')  # w_cp\n","        self.time_averaging_p = MultiInputTimeAveraging(tau=self.tau, average_at=\"after_activation\", activation='sigmoid', name='ta_p') # bias_p and the time averaging mechanism\n","\n","        # Cleanup layer\n","        self.p2c = TimeAveragedDense(tau=self.tau, average_at=\"after_activation\", units=self.c_units, activation='sigmoid', name='p2c')  # w_pc, bias_c, and the time averaging mechanism\n","        self.built = True\n","\n","    def call(self, last_o, last_h, last_p, last_c):\n","        # Hidden layer activation\n","        # h_t = tau(act(o_{t-1} @ w_oh + p_{t-1} @ w_ph + bias_h)) + (1 - tau) * h_{t-1}\n","        oh = self.o2h(last_o)  \n","        ph = self.p2h(last_p)\n","        h = self.time_averaging_h([oh, ph])\n","\n","        # Phonology layer activation\n","        # p_t = tau(act(h_{t-1} @ w_hp + p_{t-1} @ w_pp + c_{t-1} @ w_cp + bias_p)) + (1 - tau) * p_{t-1}\n","        hp = self.h2p(last_h)\n","        pp = self.p2p(last_p)\n","        cp = self.c2p(last_c)\n","        p = self.time_averaging_p([hp, pp, cp])  \n","        \n","        # Cleanup layer activation\n","        # c_t = tau(act(p_{t-1} @ w_pc + bias_c)) + (1 - tau) * c_{t-1}\n","        c = self.p2c(last_p)  \n","\n","        return h, p, c\n","\n","    def reset_states(self):  # TODO: This need another name?\n","        \"\"\"Reset time averaging history.\"\"\"\n","        self.time_averaging_p.reset_states()\n","        self.time_averaging_h.reset_states()\n","        self.p2c.reset_states()"]},{"cell_type":"markdown","metadata":{"id":"C2nd251VoYoq"},"source":["- `PMSP` is a loop that unrolls the `PMSPCell` for `n_steps` times.\n","- The inputs of `PMSP` is the orthographic representation of the word.\n","- The outputs of `PMSP` typically is the sequence of phonological representations, but we are using it to output the sequence of letter representations in this example. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtF2QwnaoYor"},"outputs":[],"source":["class PMSPLayer(tf.keras.layers.Layer):\n","    \"\"\"PMSP sim 3 model.\n","    \n","    See Plaut, McClelland, Seidenberg and Patterson (1996), simulation 3. \n","    \"\"\"\n","    def __init__(self, tau, h_units, p_units, c_units) -> None:\n","        super().__init__()\n","        self.tau = tau\n","        self.h_units = h_units\n","        self.p_units = p_units\n","        self.c_units = c_units\n","\n","    def build(self, input_shape):\n","        self.cell = PMSPCell(tau=self.tau, h_units=self.h_units, p_units=self.p_units, c_units=self.c_units)\n","        self.built = True\n","\n","    def call(self, inputs):\n","        batch_size, max_ticks, o_units = inputs.shape\n","\n","        # Initialize states\n","        h = tf.zeros((batch_size, self.cell.h_units))\n","        p = tf.zeros((batch_size, self.cell.p_units))\n","        c = tf.zeros((batch_size, self.cell.c_units))\n","\n","        # Containers for outputs with shape (batch_size, max_ticks, units)\n","        outputs_h = tf.TensorArray(dtype=tf.float32, size=max_ticks)\n","        outputs_p = tf.TensorArray(dtype=tf.float32, size=max_ticks)\n","        outputs_c = tf.TensorArray(dtype=tf.float32, size=max_ticks)\n","\n","        # Run RNN (Unrolling RNN Cell)\n","        for t in range(max_ticks):\n","            o = inputs[:, t]  # for next time tick\n","            h, p, c = self.cell(last_o=o, last_h=h, last_p=p, last_c=c)\n","            outputs_h = outputs_h.write(t, h)\n","            outputs_p = outputs_p.write(t, p)\n","            outputs_c = outputs_c.write(t, c)\n","\n","        self.cell.reset_states()\n","        \n","        outputs_h = outputs_h.stack()\n","        outputs_p = outputs_p.stack()\n","        outputs_c = outputs_c.stack()\n","        \n","        outputs_h = tf.transpose(outputs_h, [1, 0, 2])\n","        outputs_p = tf.transpose(outputs_p, [1, 0, 2])\n","        outputs_c = tf.transpose(outputs_c, [1, 0, 2])\n","        return outputs_p"]},{"cell_type":"markdown","metadata":{"id":"izyugE99oYor"},"source":["- Note that, the source code in `connectionist.layers` is not identical to the above code, which is out of the scope of this module. However, the core compute logic is the same."]},{"cell_type":"markdown","metadata":{"id":"ja-uj7DcoYor"},"source":["## Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAcrdZRpoYos"},"outputs":[],"source":["loss_fn = tf.keras.losses.BinaryCrossentropy()\n","\n","# Using a newer optimizer for faster training speed\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)  \n","\n","model.compile(optimizer=optimizer, loss=loss_fn)\n","model.fit(x_train, y_train, epochs=300, batch_size=10)  # batch_size must be provided in PMSP model"]},{"cell_type":"markdown","metadata":{"id":"-CkJUkWWoYos"},"source":["## Model evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2yyLOhOoYos"},"outputs":[],"source":["import numpy as np\n","\n","def decode_prediction(y, idx=None):\n","    \"\"\"Decode the prediction.\"\"\"\n","\n","    decoded = ''.join([letters[np.argmax(v)] for v in y])\n","    return decoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BbZCZsPoYot"},"outputs":[],"source":["y_pred = model(x_train)\n","\n","for i, word in enumerate(words):\n","    print(f\"word: {word}; pred: {decode_prediction(y_pred['phonology'][i])}\")"]},{"cell_type":"markdown","metadata":{"id":"AqEbytKNoYot"},"source":["- Notice the first letter remains constant? This is because the first letter don't have any information from O yet. Information from O start to reach P at the second time tick. \n","- The model may still struggle to predict the correct letter at tick 2, since the new information is significantly slowed down by the time-averaging mechanism. "]},{"cell_type":"markdown","metadata":{"id":"66J52jcmoYou"},"source":["### Temporal dynamics of phonology output"]},{"cell_type":"markdown","metadata":{"id":"Rubg7wm-oYou"},"source":["TODO: I think this a a good place to show more internal dynamics of the model. Discuss what to show here. e.g., hidden, cleanup. Relative input strength of PP, HP, and CP? \n","TODO: Also, think about what is the best interface to show the internal dynamics. e.g., model(x, return_internal=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Lzpj-ARoYou"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Get first prediction `cat` in proper type and shape\n","pred0 = y_pred['phonology'][0].numpy().squeeze()\n","\n","# How the prediction changes over time\n","fig, ax = plt.subplots()\n","ax.plot(pred0)\n","ax.legend(letters)\n","ax.set_xlabel('Time ticks')\n","ax.set_ylabel('Unit activation')\n","ax.set_title('Predicted temporal dynamics of the word \"cat\"')"]},{"cell_type":"markdown","metadata":{"id":"-J127C-FoYov"},"source":["### Relative input strength to phonology"]},{"cell_type":"markdown","metadata":{"id":"lV5vZ4ZpoYow"},"source":["Remember that:\n","\n","$p_t = \\tau \\times act(input_p) + (1-\\tau) p_{t-1}$\n","\n","$input_p = h_{t-1} \\cdot w_{hp} + p_{t-1} \\cdot w_{pc} + c_{t-1} \\cdot w_{cp} + b_p$\n","\n","We can break down $p_t$ into 3 parts:\n","\n","1. input from hidden to phonology = $h_{t-1} \\cdot w_{hp}$\n","2. input from phonology to phonology = $p_{t-1} \\cdot w_{pp}$\n","3. input from cleanup to phonology = $c_{t-1} \\cdot w_{cp}$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sJ7kf4fjoYow"},"source":["Let's get the internal dynamics of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"div4LFmyEPD5"},"outputs":[],"source":["model(x_train, return_internals=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H081K9SVoYox"},"outputs":[],"source":["all_outputs = model(x_train, return_internals=True)\n","print(f\"{all_outputs.keys() = }\")"]},{"cell_type":"markdown","metadata":{"id":"la_Xv8dhoYox"},"source":["See the docs for more details on `all_outputs`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crTTTOj8oYox"},"outputs":[],"source":["print(PMSP.__doc__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rT1ZddWooYoy"},"outputs":[],"source":["def plot_input_to_phonology_layer(internal_outputs, sample_idx, unit_idx):\n","    \"\"\"Plotting the inputs to phonology in selected sample and unit.\"\"\"\n","\n","    hidden = internal_outputs['hp'][sample_idx, :, unit_idx].numpy()\n","    phonology = internal_outputs['pp'][sample_idx, :, unit_idx].numpy()\n","    cleanup = internal_outputs['cp'][sample_idx, :, unit_idx].numpy()\n","\n","    fig, ax = plt.subplots()\n","    ax.plot(hidden, label='hidden to phonology')\n","    ax.plot(phonology, label='phonology to phonology')\n","    ax.plot(cleanup, label='cleanup to phonology')\n","    ax.set_xlabel('Time ticks')\n","    ax.set_ylabel('Input strength')\n","    ax.legend()\n","    ax.set_title('Relative input strength to phonology layer')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JL6FNWu3oYoy"},"source":["What is the main source of information that drives the model to produce the letter `c`?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44XvNlGRoYoy"},"outputs":[],"source":["plot_input_to_phonology_layer(all_outputs, sample_idx=words.index('cat'), unit_idx=letters.index('c'))"]},{"cell_type":"markdown","metadata":{"id":"UY_YZqwOoYoz"},"source":["How about letter `a`?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN3F9RaaoYoz"},"outputs":[],"source":["plot_input_to_phonology_layer(all_outputs, sample_idx=words.index('cat'), unit_idx=letters.index('a'))"]},{"cell_type":"markdown","metadata":{"id":"QOtBLf5qoYoz"},"source":["And the letter `t`?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpmDYF9AoYo0"},"outputs":[],"source":["plot_input_to_phonology_layer(all_outputs, sample_idx=words.index('cat'), unit_idx=letters.index('t'))"]},{"cell_type":"markdown","metadata":{"id":"p6rhndn-oYo0"},"source":["Perhaps mention division of labor and why it is important/interesting in general. "]},{"cell_type":"markdown","metadata":{"id":"RILdCxQmu1Nh"},"source":["- What main message we wants to make... \n","- Discuss other internals visualization, e.g., 2d projection of hidden layer activation over training by word\n","    - Which axis to reduce during the 2d projection\n","        - p_units? hidden_units?\n","        - time_axis? and how. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"p9q2ba2pQV8Z"},"source":["## Illustrating hidden layer representation over time ticks"]},{"cell_type":"markdown","metadata":{"id":"YVHMU6kUPypY"},"source":["- tick by tick act in all word @ hidden\n","- illustrating the representation in the hidden layer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UYaHd9gQf34"},"outputs":[],"source":["all_outputs['hidden'].shape  # Tim will help here."]},{"cell_type":"markdown","metadata":{"id":"GldEZcX250ou"},"source":["Steps\n","1. TSNE to 2d at unit axis\n","2. Plot each word in TSNE space\n","3. Animate over timetick axis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4JN_eihEPD9"},"outputs":[],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89BaDNW_4_NT"},"outputs":[],"source":["import plotly.express as px\n","import pandas as pd\n","import numpy as np\n","from sklearn.manifold import TSNE"]},{"cell_type":"markdown","metadata":{"id":"aUKMaTkAEbbC"},"source":["### Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vniPqejC6-Cy"},"outputs":[],"source":["def tsne(x: tf.Tensor) -> np.ndarray:\n","    \"\"\"Apply TSNE to output tensor on units axis.\"\"\"\n","\n","    batch_size, max_ticks, units = x.shape\n","    a = x.numpy().reshape((batch_size * max_ticks, units))\n","\n","    def _apply_tsne(array: np.ndarray) -> np.ndarray:\n","        \"\"\"Apply 2d TSNE.\"\"\"\n","        return TSNE(n_components=2).fit_transform(array)\n","\n","    return _apply_tsne(a).reshape((batch_size, max_ticks, 2))\n","\n","\n","def array2df(array: np.ndarray) -> pd.DataFrame:\n","    \"\"\"Flatten, label, normalize and cast to dataframe.\"\"\"\n","\n","    df = pd.DataFrame()\n","    for i, word in enumerate(words):\n","        for t in range(30):\n","            case_df = pd.DataFrame(\n","                {\n","                    \"word\": word,\n","                    \"timetick\": t,\n","                    \"tsne_a1\": array[i, t, 0],\n","                    \"tsne_a2\": array[i, t, 1]\n","                },\n","                index = [0]\n","            )\n","            df = pd.concat([df, case_df], ignore_index=True)\n","\n","    # Character labels\n","    df['char1'] = df.word.str[0]\n","    df['char2'] = df.word.str[1]\n","    df['char3'] = df.word.str[2]\n","\n","    # Normalize\n","    def normalize(x:pd.Series) -> pd.Series:\n","        \"\"\"Normalize to 0-1 range.\"\"\"\n","        return (x-min(x))/(max(x)-min(x))\n","\n","    df['tsne_a1'] = normalize(df.tsne_a1)\n","    df['tsne_a2'] = normalize(df.tsne_a2)\n","\n","    return df\n","\n"]},{"cell_type":"markdown","metadata":{"id":"r40k91vYElA3"},"source":["Test on phonological representation to make sure reshaping is somewhat correct? \n","TODO: Need extra checking in reshape..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fS0BGgnSBghD"},"outputs":[],"source":["# Run the tidying pipeline\n","p_tsne = tsne(all_outputs['phonology'])\n","df = array2df(p_tsne)\n","df"]},{"cell_type":"markdown","metadata":{"id":"FhLW85TbFOBF"},"source":["Plot the animated 2d tsne scatter "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Du9CILHA6DU8"},"outputs":[],"source":["px.scatter(\n","    df, x=\"tsne_a1\", y=\"tsne_a2\", \n","    animation_frame=\"timetick\", animation_group=\"word\",\n","    color=\"char2\", hover_name=\"word\", \n","    range_x=[0, 1], range_y=[0,1], \n","    width=800, height=800,\n","    title=\"How predicted phonological representation cluster over time\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"BTSZSrZcFsY0"},"source":["- Character 2 clustering is very good (group together between 10-20 ticks, where it should be)"]},{"cell_type":"markdown","metadata":{"id":"u_RTytYFGPXG"},"source":["Plot the same thing, but on hidden representation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJKlB0fXF9sh"},"outputs":[],"source":["df = array2df(tsne(all_outputs['hidden']))\n","\n","px.scatter(\n","    df, x=\"tsne_a1\", y=\"tsne_a2\", \n","    animation_frame=\"timetick\", animation_group=\"word\",\n","    color=\"char2\", hover_name=\"word\", \n","    range_x=[0, 1], range_y=[0,1], \n","    width=800, height=800,\n","    title=\"How hidden representation cluster over time\"\n",")"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"f55368bc7be0f2238dbef0a99c4d07d77945e5a459017dc2b141ca990cb81374"}}},"nbformat":4,"nbformat_minor":0}